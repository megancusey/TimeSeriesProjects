table.purchaseprice
## Proportions
round(prop.table(table.purchaseprice),2)*100
barplot(table.purchaseprice[order(table.purchaseprice,decreasing = TRUE)],
main="Frequencies of Purchase Price in \n car evaluation dataset",
xlab="Type of Purchase Price",
ylab="Frequency of Purchase Price")
table.maintenancecost <- table(data$Maintenance.Costs)
##Maintenance Cost
## Frequencies
table.maintenancecost <- sort(table.maintenancecost, decreasing=TRUE)
table.maintenancecost
## Proportions
round(prop.table(table.purchaseprice),2)*100
barplot(table.maintenancecost[order(table.maintenancecost,decreasing = TRUE)],
main="Frequencies of Maintenance Cost in \n car evaluation dataset",
xlab="Type of Maintenance Cost",
ylab="Frequency of Maintenance Cost")
## Frequencies
table.maintenancecost <- sort(table.maintenancecost, decreasing=TRUE)
table.maintenancecost
## Proportions
round(prop.table(table.maintenancecost),2)*100
table.doors <- table(data$Doors)
## Doors
## Frequencies
table.doors <- sort(table.doors, decreasing=TRUE)
table.doors
## Proportions
round(prop.table(table.doors),2)*100
barplot(table.doors[order(table.doors,decreasing = TRUE)],
main="Frequencies of Number of Doors in \n car evaluation dataset",
xlab="Number of Doors",
ylab="Frequency of Number of Doors")
table.persons <- table(data$Persons)
## Persons
## Frequencies
table.persons <- sort(table.persons, decreasing=TRUE)
table.persons
## Proportions
round(prop.table(table.persons),2)*100
barplot(table.persons[order(table.persons,decreasing = TRUE)],
main="Frequencies of Number of Persons in \n car evaluation dataset",
xlab="Number of Persons",
ylab="Frequency of Number of Persons")
## RATINGS
barplot(table.ratings[order(table.ratings,decreasing = TRUE)],
main="Frequencies of Ratings in \n car evaluation dataset",
xlab="Type of Rating",
ylab="Frequency of Rating")
## Proportions
round(prop.table(table.ratings),2)*100
barplot(table.ratings[order(table.purchaseprice,decreasing = TRUE)],
main="Frequencies of Ratings in \n car evaluation dataset",
xlab="Type of Rating",
ylab="Frequency of Rating")
barplot(table.ratings[order(table.purchaseprice,decreasing = TRUE)],
main="Frequencies of Ratings in \n car evaluation dataset",
xlab="Type of Rating",
ylab="Frequency of Rating")
rm(list=ls())
library(dplyr)
library(rpart)
library(rpart.plot)
library(e1071)
install.packages("dplyr")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart.plot")
install.packages("e1071")
library(dplyr)
library(rpart)
library(rpart.plot)
library(e1071)
library("rpart", lib.loc="C:/Program Files/Microsoft/R Client/R_SERVER/library")
set.seed(678)
titanic <- read.csv("Titanic Data.csv")
head(titanic)
## gets last 6 rows
tail(titanic)
shuffle_index <- sample(1:nrow(titanic))
shuffle_index
head(shuffle_index)
titanic <- titanic[shuffle_index, ]
head(titanic)
# Clean the data - more straightforward approach than in blog post
titanic1 <- titanic[ ,-c(1,4,9,11,13)]
titanic1$pclass <- factor(titanic1$pclass, levels = c(1,2,3), labels = c('Upper', 'Middle', 'Lower'))
titanic1$survived <- factor(titanic1$survived, levels = c(0,1), labels = c('No', 'Yes'))
titanic1 <- na.omit(titanic1)
clean_titanic <- titanic1
glimpse(clean_titanic)
create_train_test <- function(data, size = 0.8, train = TRUE) {
## I assume get the count of rows from data
n_row = nrow(data)
## get the # of rows needed for the test/train set
total_row = size * n_row
## assigns the appropriate amount of rows to the output data
train_sample <-  1: total_row
if (train == TRUE) {
return (data[train_sample, ])
} else {
return (data[-train_sample, ])
}
}
data_train <- create_train_test(clean_titanic, 0.8, train = TRUE)
data_test <- create_train_test(clean_titanic, 0.8, train = FALSE)
dim(data_train)
dim(data_test)
prop.table(table(data_train$survived))
prop.table(table(data_test$survived))
fit <- rpart(survived~., data = data_train, method = 'class')
rpart.plot(fit, extra = 106)
predict_unseen <-predict(fit, data_test, type = 'class')
table_mat <- table(data_test$survived, predict_unseen)
table_mat
accuracy_Test <- sum(diag(table_mat)) /sum(table_mat)
print(paste('Accuracy for test', accuracy_Test))
fitnb <- naiveBayes(survived~., data= data_train)
View(fitnb)
View(fitnb)
predictnb <- predict(fitnb, data_test)
table_mat_nb <- table(data_test$survived, predictnb)
table_mat_nb
accuracy_Test_nb <- sum(diag(table_mat_nb)) /sum(table_mat_nb)
print(paste('Accuracy for test Naive Bayes', accuracy_Test_nb))
#Naive Bayes
fitnb <- naiveBayes(survived~., data= data_train)
predictnb <- predict(fitnb, data_test)
table_mat_nb <- table(data_test$survived, predictnb)
table_mat_nb
accuracy_Test_nb <- sum(diag(table_mat_nb)) /sum(table_mat_nb)
print(paste('Accuracy for test Naive Bayes', accuracy_Test_nb))
print(paste('Accuracy for test', accuracy_Test))
print(paste('Accuracy for test Naive Bayes', accuracy_Test_nb))
retaildata <- readxl::read_excel("retail.xlsx", skip=1)
rm(list = ls())
retaildata <- readxl::read_excel("retail.xlsx", skip=1)
retaildata <- readxl::read_excel("retail.xlsx", skip=1)
myts <- ts(retaildata[,"A3349873A"],
frequency=12, start=c(1982,4))
autoplot(myts)
library("ggplot2", lib.loc="~/R/win-library/3.3")
autoplot(myts)
autoplot()
autoplotretaildata([,"A3349873A"])
autoplot(retaildata[,"A3349873A"])
autoplot(myts)
ggseasonplot(myts, year.labels=TRUE, year.labels.left=TRUE)
myts <- ts(retaildata[,"A3349873A"],
frequency=12, start=c(1982,4))
autoplot(myts)
library(ggplot2)
##retaildata <- readxl::read_excel("retail.xlsx", skip=1)
##myts <- ts(retaildata[,"A3349873A"],
frequency=12, start=c(1982,4))
autoplot(myts)
library(ggplot2)
##retaildata <- readxl::read_excel("retail.xlsx", skip=1)
##myts <- ts(retaildata[,"A3349873A"],
##           frequency=12, start=c(1982,4))
autoplot(myts)
View(retaildata)
View(retaildata)
library(ggplot2)
retaildata <- readxl::read_excel("retail.xlsx", skip=1)
myts <- ts(retaildata[,"A3349873A"],
frequency=12, start=c(1982,4))
View(retaildata)
View(retaildata)
ggseasonplot(myts, year.labels=TRUE, year.labels.left=TRUE)
install.packages("installr")
library(installr) # install+load installr
updateR() # updating R.
rm(list = ls())
library(fma)
plot(fancy)
library(fpp2)
autoplot(fancy)
fancy_data < - fancy
fancy_data <- fancy
fancy_data
tslm(fancy ~ trend + season)
log.fancy <- log(fancy)
dummy.fest = rep(0, length(fancy))
dummy.fest[seq_along(dummy.fest)%% 12 == 3] <- 1
dummy.fest[3]
dummy.fest
dummy.fest = rep(0, length(fancy))
dummy.fest[seq_along(dummy.fest)%% 12 == 3] <- 1
## create dummy fest as a time series object
dummy.fest <- ts(dummy.fest, freq=12, start=c(1987,1))
## combine data
data <- data.frame(log.fancy, dummy.fest)
View(data)
View(data)
tslm(fancy ~ trend + season + dummy.fest data=data)
## combine data
model_data <- data.frame(log.fancy, dummy.fest)
tslm(fancy ~ trend + season + dummy.fest data=model_data)
tslm(fancy ~ trend + season + dummy.fest, data=model_data)
fit.fancy <- tslm(fancy ~ trend + season + dummy.fest, data=model_data)
autoplot(fancy, series="Data") +
autolayer(fitted(fit.fancy), series="Fitted") +
xlab("Year") + ylab("Sales")
plot(residuals(fit.fancy), type='p')
checkresiduals(fit.fancy)
dummy.fest[3] <- 0
## transform sales data with log of sales
log.fancy <- log(fancy)
## create dummy variable for surfing festival
dummy.fest = rep(0, length(fancy))
dummy.fest[seq_along(dummy.fest)%% 12 == 3] <- 1
## March 1987 didn't have a festival
dummy.fest[3] <- 0
## create dummy fest as a time series object
dummy.fest <- ts(dummy.fest, freq=12, start=c(1987,1))
## combine data
model_data <- data.frame(log.fancy, dummy.fest)
## create regression line
fit.fancy <- tslm(fancy ~ trend + season + dummy.fest, data=model_data)
## Plot regression model fitted vs data
autoplot(fancy, series="Data") +
autolayer(fitted(fit.fancy), series="Fitted") +
xlab("Year") + ylab("Sales") +
ggtitle("Fancy Sales/Year")
checkresiduals(fit.fancy)
plot(log.fancy)
autoplot(fit.fancy$residuals)
plot(as.numeric(fitted(fit.fancy)), residuals(fit), type='p')
plot(as.numeric(fitted(fit.fancy)), residuals(fit.fancy), type='p')
autoplot(fit.fancy$residuals)
boxplot(resid(fit.fancy) ~ cycle(resid(fit.fancy)))
summary(fit.fancy)
checkresiduals(fit.fancy)
future.data <- data.frame(dummy.fest = rep(0,36))
forecast.fancy <- forecast(fit.fancy, newdata=future.data)
View(future.data)
View(future.data)
View(forecast.fancy)
View(forecast.fancy)
plot(forecast.fancy)
summary(forecast.fancy)
data <- as.data.fram(forecast.fancy)
data <- exp(data) ## transform back from log
data <- as.data.frame(forecast.fancy)
data <- exp(data) ## transform back from log
data
data <- as.data.frame(forecast.fancy)
data <- exp(data) ## transform back from log
data
data <- as.data.frame(exp(forecast.fancy))
exp(forecast.fancy)
summary(forecast.fancy)
data <- as.data.frame(forecast.fancy)
data <- exp(data$forecast)
data <- exp(data$`Point Forecast`)
data
library(fma)
library(fpp2)
rm(list = ls())
autoplot(plastics)
plastics %>% decompose(type="multiplicative") %>%
autoplot() + xlab("Year") +
ggtitle("Classical multiplicative decomposition
of product A ")
autoplot(plastics)
autoplot(plastics)
plastics %>% decompose(type="multiplicative") %>%
autoplot() + xlab("Year") +
ggtitle("Classical multiplicative decomposition
of product A ")
decomp_plastics <- decompose(plastics, type="multiplicative")
autoplot(plastics,series="Data") +
autolayer(seasadj(decomp_plastics), series="Seasonally Adjusted") +
xlab("Year") + ylab("Monthly Sales")
plastics
outlier.plastics[1] <- 5000
outlier.plastics <- plastics
outlier.plastics[1] <- 5000
decompose_outlier_plastics <- decompose(outlier.plastics, type="multiplicative")
autoplot(outlier.plastics, series="Data") +
autolayer(trendcycle(decompose_outlier_plastics), series="trend") +
autolayer(seasadj(decompose_outlier_plastics), series="seasonally adjusted") +
xlab("Year") + ylab("Monthly Sales")
decompose_outlier_plastics <- decompose(outlier.plastics, type="multiplicative")
autoplot(outlier.plastics, series="Data") +
autolayer(trendcycle(decompose_outlier_plastics), series="trend") +
autolayer(seasadj(decompose_outlier_plastics), series="seasonally adjusted") +
xlab("Year") + ylab("Monthly Sales")
outlier.plastics <- plastics
outlier.plastics[1] <- 2500
decompose_outlier_plastics <- decompose(outlier.plastics, type="multiplicative")
autoplot(outlier.plastics, series="Data") +
autolayer(trendcycle(decompose_outlier_plastics), series="trend") +
autolayer(seasadj(decompose_outlier_plastics), series="seasonally adjusted") +
xlab("Year") + ylab("Monthly Sales")
outlier.plastics <- plastics
outlier.plastics[1] <- 1400
decompose_outlier_plastics <- decompose(outlier.plastics, type="multiplicative")
autoplot(outlier.plastics, series="Data") +
autolayer(trendcycle(decompose_outlier_plastics), series="trend") +
autolayer(seasadj(decompose_outlier_plastics), series="seasonally adjusted") +
xlab("Year") + ylab("Monthly Sales")
autoplot(plastics,series="Data") +
autolayer(seasadj(decomp_plastics), series="Seasonally Adjusted") +
xlab("Year") + ylab("Monthly Sales")
outlier.middle.plastics <- plastics
outlier.middle.plastics
outlier.middle.plastics <- plastics
outlier.middle.plastics[30] <- 500
decompose.outlier.middle.plastics <- decompose(outlier.middle.plastics, type="multiplicative")
autoplot(outlier.middle.plastics, series="Data") +
autolayer(trendcycle(decompose.outlier.middle.plastics), series="trend") +
autolayer(seasadj(decompose.outlier.middle.plastics), series="seasonally adjusted") +
xlab("Year") + ylab("Monthly Sales")
outlier.end.plastics <- plastics
outlier.end.plastics[59] <- 2000
decompose.outlier.end.plastics <- decompose(outlier.end.plastics, type="multiplicative")
autoplot(outlier.end.plastics, series="Data") +
autolayer(trendcycle(decompose.outlier.end.plastics), series="trend") +
autolayer(seasadj(decompose.outlier.end.plastics), series="seasonally adjusted") +
xlab("Year") + ylab("Monthly Sales")
rm(list = ls())
library(fma)
library(fpp2)
books.original <- books
autoplot(books.original)
autoplot(books.original) +
xlab("Day") +
ylab("Book Sales") +
ggtitle("Daily Book Sales for Paperback and Hardcover Books")
books.ses = ses(books.original, h=5)
autoplot(books.ses) +
autolayer(fitted(session.ses), series="Fitted")
books.ses = ses(books.original, h=5)
books.ses = ses(books.original, h=5)
books.original
books.ses = ses(books.original(,'Paperback'), h=5)
books.ses = ses(books.original$Paperback, h=5)
books.ses = ses(books.original[,'Paperback'], h=5)
books.ses.paperback = ses(books.original[,'Paperback'], h=5)
books.ses.hardcover = ses(books.original[,'Hardcover'], h=5)
autoplot(books.ses) +
autolayer(fitted(books.ses.paperback), series="Paperback Fitted") +
autolayer(fitted(books.ses.hardcover), series="Hardcover Fitted Data")
autoplot(books.original) +
autolayer(fitted(books.ses.paperback), series="Paperback Fitted") +
autolayer(fitted(books.ses.hardcover), series="Hardcover Fitted Data")
autoplot(books.ses.paperback) +
autolayer(fitted(books.ses.paperback), series="Paperback Fitted")
autoplot(books.ses.hardcover) +
autolayer(fitted(books.ses.hardcover), series="Hardcover Fitted Data")
round(accuracy(books.ses.paperback),2)
round(accuracy(books.ses.hardcover),2)
books.holt.paperback <- holt(books.original[,'Paperback'])
books.holt.hardcover <- holt(books.original[,'Hardcover'])
books.holt.paperback <- holt(books.original[,'Paperback'], h=4)
books.holt.hardcover <- holt(books.original[,'Hardcover'], h=4)
autoplot(books.original[,'Paperback']) +
autolayer(books.holt.paperback, series="Holt's Method", PI=FALSE)
autoplot(books.original[,'Hardcover']) +
autolayer(books.holt.hardcover, series="Holt's Method", PI=FALSE)
round(accuracy(books.holt.paperback),2)
round(accuracy(books.holt.hardcover),2)
round(accuracy(books.holt.hardcover),2)
View(books.ses.hardcover)
View(books.ses.hardcover)
autoplot(books.original[,'Paperback']) +
autolayer(books.holt.paperback, series="Holt's Method", PI=FALSE)
autoplot(books.ses.paperback) +
autolayer(fitted(books.ses.paperback), series="Paperback Fitted")
books.ses.paperback$upper[1,'95%']
books.ses.paperback$lower[1,'95%']
books.ses.paperback.rsme <- round(accuracy(books.ses.paperback),2)
## Paperback RSME = 33.64
books.ses.hardcover.rsme <- round(accuracy(books.ses.hardcover),2)
## Hardcover RSME = 31.93
books.holt.paperback.rsme <- round(accuracy(books.holt.paperback),2)
## Paperback RSME = 31.14
books.holt.hardcover.rsme <- round(accuracy(books.holt.hardcover),2)
## Hardcover RSME = 27.19
books.ses.paperback$mean+1.96*
##2
## The plastics data set consists of the monthly sales (in thousands)
## of product A for a plastics manufacturer for five years.
## a. Plot the time series of sales of product A.
##    Can you identify seasonal fluctuations and/or a trend-cycle?
autoplot(plastics)
plastics %>% decompose(type="multiplicative") %>%
autoplot() + xlab("Year") +
ggtitle("Classical multiplicative decomposition
of product A ")
books.ses.paperback$upper[1,'95%']
books.ses.paperback$lower[1,'95%']
books.ses.paperback$mean+1.96* books.ses.paperback.rsme
books.ses.paperback$mean-1.96* books.ses.paperback.rsme
books.ses.paperback$mean + 1.96 * books.ses.paperback.rsme
books.ses.paperback$mean - 1.96 * books.ses.paperback.rsme
books.ses.paperback$mean[1] + 1.96 * books.ses.paperback.rsme
books.ses.paperback$mean[1] - 1.96 * books.ses.paperback.rsme
books.ses.paperback$mean[1] - 1.96 * books.ses.paperback.rsme
s <- sqrt(books.holt.paperback$model$mse)
s
View(books.holt.hardcover)
low <- books.holt.paperback$mean[1] - 1.96 * s
books.holt.hardcover
books.holt.paperback
c(low = low, high= high)
high <- books.holt.paperback$mean[1] + 1.96 * s
c(low = low, high= high)
s <- sqrt(books.holt.hardcover$model$mse)
high <- books.holt.hardcover$mean[1] + 1.96 * s
low <- books.holt.hardcover$mean[1] - 1.96 * s
books.holt.hardcover
c(low = low, high= high)
books.holt.paperback.level <- holt(books.original[,'Paperback'], h=4, level =95)
books.holt.paperback.level
books.holt.paperback
books.holt.hardcover
books.holt.paperback
rm(list = ls())
library(fma)
imbclose.data <- ibmclose
autoplot(imbclose.data)
ggAcf(imbclose.data)
ggPacf(imbclose.data)
library(expsmooth)
library(expsmooth)
BoxCox(usnetelec, BoxCox.lambda(usnetelec))
autoplot(usnetelec)
autoplot(usnetelec.transformed)
usnetelec.transformed <- BoxCox(usnetelec, BoxCox.lambda(usnetelec))
autoplot(usnetelec.transformed)
diff(usnetelec)
autoplot(diff(usnetelec))
autoplot(diff(usnetelec.transformed))
rm(list = ls())
source('C:/Users/cusey/source/repos/TimeSeriesProjectts/TimeSeriesProjects/TimeSeriesProjects/code snippets.R', echo=TRUE)
library(urca)
rm(list = ls())
library(expsmooth)
library(urca)
usnetelec.transformed <- BoxCox(usnetelec, BoxCox.lambda(usnetelec))
autoplot(usnetelec) ## upward trend
autoplot(usnetelec.transformed) ## Still upward trend, no real seasonality
autoplot(diff(usnetelec))
autoplot(diff(usnetelec.transformed))
usnetelec %>% ur.kpss() %>% summary()
usnetelec.transformed %>% ur.kpss() %>% summary()
usnetelec.transformed %>% diff() %>% ur.kpss() %>% summary()
## indicates not stationary
usnetelec %>% diff() %>% ur.kpss() %>% summary()
## indicates not stationary
usgpd
library(expsmooth)
mywd()
getwd()
data <- read.csv("retail-csv.csv", skip = 1)
setwd("C:/Users/cusey/Source/Repos/TimeSeriesProjectts/TimeSeriesProjects/TimeSeriesProjects")
data <- read.csv("retail-csv.csv", skip = 1)
myts <- ts(data[, "A3349873A"],
frequency = 12, start = c(1982, 4))
library(fma)
autoplot(myts)
myts.transformed <- BoxCox(myts, BoxCox.lambda(myts))
autoplot(myts.transformed)
myts.transformed.seasonaldif <- myts.transformed %>% diff(lag=12) %>% ggtsdisplay()
myts.transformed.seasonaldif %>% summary()
library(urca)
myts.transformed.seasonaldif ur.kpss() %>% summary()
myts.transformed.seasonaldif %>% ur.kpss() %>% summary()
myts.transformed.seasonaldif %>%  ur.kpss() %>% summary()
myts.transformed %>% diff(lag=12) %>% ur.kpss() %>% summary()
autoplot(usgdp)
usgdp %>% diff() %>% ggtsdisplay()
usgdp %>% diff() %>% ggtsdisplay()
usgdp %>% diff() %>% ur.kpss() %>% summary()
usgdp %>% BoxCox(BoxCox.lambda()) %>% diff() %>% ggtsdisplay()
BoxCox(usgdp,BoxCox.lambda()) %>% diff() %>% ggtsdisplay()
BoxCox(usgdp,BoxCox.lambda(usgdp)) %>% diff() %>% ggtsdisplay()
BoxCox(usgdp,BoxCox.lambda(usgdp)) %>%  ur.kpss() %>% summary()
BoxCox(usgdp,BoxCox.lambda(usgdp)) %>% diff() %>%  ur.kpss() %>% summary()
usnetelec %>% diff()
usnetelec %>% diff() %>% ur.kpss() %>% summary()
myts.transformed %>% diff(lag=12) %>% ur.kpss() %>% summary()
myts.transformed %>% diff(lag=12) %>% diff() %>% ur.kpss() %>% summary()
autoplot(mcopper)
mcopper %>% log()
mcopper %>% log() %>% autoplot()
mcopper %>% log() %>% diff() %>% autoplot()
mcopper %>% log() %>% diff() %>% ur.kpss %>% summary()
autoplot(enplanements)
enplanements %>% log() %>% diff(lag=12) %>% autoplot()
enplanements %>% log() %>% diff(lag=12) %>% ur.kpss %>% summary()
enplanements %>% log() %>% diff(lag=12) %>% diff(lag=12) %>% ur.kpss %>% summary()
enplanements %>% log() %>% diff(lag=12) %>% diff() %>% ur.kpss %>% summary()
## e. visitors
autoplot(visitors)
visitors %>% log() %>% diff(lag=12) %>% autoplot()
visitors %>% log() %>% diff(lag=12) %>% diff() %>% autoplot()
visitors %>% log() %>% diff(lag=12) %>% diff() %>% ur.kpss %>% summary()
